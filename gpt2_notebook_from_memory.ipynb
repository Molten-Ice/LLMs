{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "sd_hf = model_hf.state_dict()\n",
    "\n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('asimov.txt', 'r') as f:\n",
    "    asimov = f.read()\n",
    "asimov = asimov[:1000]\n",
    "print(asimov[37:565])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer.encode(\"Hello Hari Seldon!\")\n",
    "\n",
    "tokenizer.decode(tokenizer.encode(\"Hello Hari Seldon!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "# transformer.wte.weight torch.Size([50257, 768])\n",
    "# transformer.wpe.weight torch.Size([1024, 768])\n",
    "\n",
    "# transformer.h.0.ln_1.weight torch.Size([768])\n",
    "# transformer.h.0.ln_1.bias torch.Size([768])\n",
    "# transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
    "# transformer.h.0.attn.c_attn.bias torch.Size([2304])\n",
    "# transformer.h.0.attn.c_proj.weight torch.Size([768, 768])\n",
    "# transformer.h.0.attn.c_proj.bias torch.Size([768])\n",
    "# transformer.h.0.ln_2.weight torch.Size([768])\n",
    "# transformer.h.0.ln_2.bias torch.Size([768])\n",
    "# transformer.h.0.mlp.c_fc.weight torch.Size([768, 3072])\n",
    "# transformer.h.0.mlp.c_fc.bias torch.Size([3072])\n",
    "# transformer.h.0.mlp.c_proj.weight torch.Size([3072, 768])\n",
    "# transformer.h.0.mlp.c_proj.bias torch.Size([768])\n",
    "\n",
    "# transformer.h.11.ln_1.weight torch.Size([768])\n",
    "# transformer.h.11.ln_1.bias torch.Size([768])\n",
    "# transformer.h.11.attn.c_attn.weight torch.Size([768, 2304])\n",
    "# transformer.h.11.attn.c_attn.bias torch.Size([2304])\n",
    "# transformer.h.11.attn.c_proj.weight torch.Size([768, 768])\n",
    "# transformer.h.11.attn.c_proj.bias torch.Size([768])\n",
    "# transformer.h.11.ln_2.weight torch.Size([768])\n",
    "# transformer.h.11.ln_2.bias torch.Size([768])\n",
    "# transformer.h.11.mlp.c_fc.weight torch.Size([768, 3072])\n",
    "# transformer.h.11.mlp.c_fc.bias torch.Size([3072])\n",
    "# transformer.h.11.mlp.c_proj.weight torch.Size([3072, 768])\n",
    "# transformer.h.11.mlp.c_proj.bias torch.Size([768])\n",
    "\n",
    "# transformer.ln_f.weight torch.Size([768])\n",
    "# transformer.ln_f.bias torch.Size([768])\n",
    "# lm_head.weight torch.Size([50257, 768])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "768*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# ---- #\n",
    "\n",
    "batch_size = 64\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "dropout = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.44 Million parameters\n",
      "خ him2ʎ whatction not� just can Ain�icoitionnt off��ind�\u0010Dly whose hin�\u0001ces).ice\u0011 shigc5 ag so\u0018 d\u0017..f\u0011an alberredect� mayonsormforeim see scXon� Eob� kces eromvery 6 yearall�t am?usm�� kroizom aboutasport with Eockul Theond��\u001f�quick butantusachTam otherownastance con�b�� but�threatine� t@�\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50257\n",
    "    n_layers: int = 12\n",
    "    n_heads: int = 6\n",
    "    n_embed: int = 768\n",
    "\n",
    "# @dataclass\n",
    "# class GPTConfig:\n",
    "#     block_size: int = 1024\n",
    "#     vocab_size: int = 50257\n",
    "#     n_layers: int = 2\n",
    "#     n_heads: int = 2\n",
    "#     n_embed: int = 100\n",
    "\n",
    "config = GPTConfig()\n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embed, config.n_embed * 4)\n",
    "        self.c_proj = nn.Linear(config.n_embed * 4, config.n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_heads = config.n_heads\n",
    "        self.head_size = config.n_embed // config.n_heads\n",
    "        self.c_attn = nn.Linear(config.n_embed, 3 * config.n_embed) # Why is matrix shaped ([2304, 768])\n",
    "        self.c_proj = nn.Linear(config.n_embed, config.n_embed)\n",
    "\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.block_size, config.block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = self.c_attn(x)\n",
    "\n",
    "        proj = x.view(B, self.n_heads, T, self.head_size*3)\n",
    "        k, q, v = proj.split(self.head_size, dim=-1)\n",
    "\n",
    "        wei = k @ q.transpose(-2, -1) * self.head_size**-0.5\n",
    "        # Add triangle\n",
    "\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        out = wei @ v\n",
    "        out = out.view(B, T, C)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Multiple head attention\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_heads = config.n_heads\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embed)\n",
    "        self.attn = Attention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embed)\n",
    "        self.mlp = MultiLayerPerceptron(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embed),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embed),\n",
    "            h = nn.ModuleList([Block(config) for _ in range(config.n_layers)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embed),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embed, config.vocab_size, bias=False),\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # x: (B, T, C)\n",
    "        B, T = x.shape\n",
    "        tok_emb = self.transformer.wte(x)\n",
    "        pos_emb = self.transformer.wpe(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "\n",
    "        logits = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -config.block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "       \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "model = GPT(config).to(device)\n",
    "print(f'{sum(p.numel() for p in model.parameters())/1e6:.2f} Million parameters')\n",
    "\n",
    "context = torch.randint(0, config.vocab_size, (1, 2), device=device)\n",
    "print(tokenizer.decode(model.generate(context, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.37 Million parameters\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokens = tokenizer.encode(\"What the dog doin¿\")\n",
    "x = torch.tensor(tokens).view(1, -1)\n",
    "out = model(x)\n",
    "print(out.shape)\n",
    "decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (key, param), (key_hf, v_hf) in zip(model.named_parameters(), sd_hf.items()):\n",
    "#     # print(f'{key}: {param.shape} vs {key_hf}: {v_hf.shape}')\n",
    "#     assert key == key_hf, f'{key} != {key_hf}'\n",
    "#     if param.shape == v_hf.shape:\n",
    "#         pass\n",
    "#     elif param.shape[0] == v_hf.shape[1] and param.shape[1] == v_hf.shape[0]:\n",
    "#         print(f'{key}: {param.shape} is transposed')\n",
    "#     else:\n",
    "#         raise ValueError(f'{param.shape} != {v_hf.shape}, key: {key}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer.h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
    "# transformer.h.0.attn.c_attn.bias torch.Size([2304])\n",
    "# transformer.h.0.attn.c_proj.weight torch.Size([768, 768])\n",
    "# transformer.h.0.attn.c_proj.bias torch.Size([768])\n",
    "\n",
    "\n",
    "attn = Attention(config)\n",
    "x = torch.randn(3, 20, 768)\n",
    "attn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_embed, config.n_heads\n",
    "head_size = config.n_embed // config.n_heads\n",
    "head_size*18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 20, 2304)\n",
    "# (3, 20, 2304), (B, T, head_size*n_heads*3)\n",
    "# -> (B, n_heads, T, head_size*3)\n",
    "print(f'x.shape: {x.shape}')\n",
    "B, T, C = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  print(B, T, self.n_heads, self.head_size*3)\n",
    "    k, q, v = x.view(B, T, self.n_heads, self.head_size*3), .split(self.head_size, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
